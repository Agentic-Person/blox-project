{
  "name": "üìö Transcript Indexer",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "transcript-indexer",
        "responseMode": "lastNode",
        "responseData": "allEntries",
        "options": {}
      },
      "id": "a1b2c3d4-e5f6-7890-a123-456789012345",
      "name": "üì• Transcript Indexer Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [280, 400],
      "webhookId": "transcript-indexer-webhook",
      "onError": "continueRegularOutput",
      "notes": "üö™ MAIN ENTRY POINT - Transcript Indexer Webhook\n\nüéØ PURPOSE:\nHandles video transcript processing and embedding generation:\n‚Ä¢ Processes raw video transcripts with timestamps\n‚Ä¢ Splits long transcripts into semantic chunks\n‚Ä¢ Generates embeddings using OpenAI models\n‚Ä¢ Stores vectors in PGVector database for similarity search\n‚Ä¢ Returns indexing status and metadata\n\nüìù EXPECTED PAYLOAD:\n{\n  \"videoId\": \"string\", // Unique video identifier\n  \"title\": \"string\", // Video title for context\n  \"transcript\": \"string\", // Full transcript text with timestamps\n  \"metadata\": {\n    \"duration\": \"number\", // Video length in seconds\n    \"module\": \"string\", // Learning module (e.g., \"Roblox Basics\")\n    \"week\": \"number\", // Week number in curriculum\n    \"tags\": [\"array\"], // Topic tags for categorization\n    \"difficulty\": \"beginner|intermediate|advanced\"\n  },\n  \"forceReindex\": \"boolean\" // Skip existing check if true\n}\n\n‚úÖ PROCESSING FEATURES:\n‚Ä¢ Intelligent text chunking with timestamp preservation\n‚Ä¢ Duplicate detection and handling\n‚Ä¢ Metadata enrichment for better search context\n‚Ä¢ Progress tracking with detailed logging\n‚Ä¢ Error recovery and retry mechanisms\n\nüîÑ FLOW:\nWebhook ‚Üí Validation ‚Üí Duplicate Check ‚Üí Text Processing ‚Üí Embedding Generation ‚Üí Vector Storage ‚Üí Response"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "required_fields_check",
              "leftValue": "={{ $json.videoId && $json.transcript && $json.title }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equal"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "b2c3d4e5-f6a7-8901-b234-567890123456",
      "name": "‚úÖ Input Validator",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [500, 400],
      "onError": "continueRegularOutput",
      "notes": "üîç INPUT VALIDATION CHECKPOINT\n\nüéØ PURPOSE:\nValidates incoming transcript indexing requests:\n‚Ä¢ videoId: Unique identifier for the video\n‚Ä¢ transcript: Raw transcript text with timestamps\n‚Ä¢ title: Video title for context and search enhancement\n‚Ä¢ metadata: Optional but recommended for better search\n\n‚úÖ VALIDATION RULES:\n‚Ä¢ Required fields present and non-empty\n‚Ä¢ VideoId format validation (alphanumeric + hyphens)\n‚Ä¢ Transcript minimum length check (> 10 characters)\n‚Ä¢ Title length validation (< 200 characters)\n‚Ä¢ Metadata structure validation if provided\n\nüìä ADDITIONAL CHECKS:\n‚Ä¢ Transcript format validation (timestamp patterns)\n‚Ä¢ Video duration reasonableness (> 0, < 86400 seconds)\n‚Ä¢ Module/week validation against curriculum structure\n‚Ä¢ Tag validation (predefined topic categories)\n‚Ä¢ Difficulty level enum validation\n\n‚ùå FAILURE HANDLING:\n‚Ä¢ Invalid requests ‚Üí Error Response with specific field issues\n‚Ä¢ Missing fields ‚Üí 400 Bad Request with field list\n‚Ä¢ Malformed data ‚Üí Sanitization attempt or rejection\n‚Ä¢ Security violations ‚Üí Rate limiting and alert\n\nüîí SECURITY FEATURES:\n‚Ä¢ Input sanitization to prevent injection\n‚Ä¢ Content length limits to prevent abuse\n‚Ä¢ Rate limiting per IP address\n‚Ä¢ Audit logging for all requests\n\n‚û°Ô∏è ROUTING:\nValid ‚Üí Continue to Duplicate Check\nInvalid ‚Üí Error Response Handler"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT id, created_at, embedding_count FROM video_transcripts WHERE video_id = '{{ $json.videoId }}' AND status = 'indexed' ORDER BY created_at DESC LIMIT 1;",
        "options": {}
      },
      "id": "c3d4e5f6-a7b8-9012-c345-678901234567",
      "name": "üîç Check Existing Index",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [720, 400],
      "credentials": {
        "postgres": {
          "id": "postgres-credentials",
          "name": "Postgres Credentials"
        }
      },
      "onError": "continueRegularOutput",
      "notes": "üîç DUPLICATE INDEX DETECTION\n\nüéØ PURPOSE:\nChecks if video transcript is already indexed to prevent duplicates:\n‚Ä¢ Queries PGVector database for existing video_id\n‚Ä¢ Returns existing index metadata if found\n‚Ä¢ Enables smart reindexing decisions\n‚Ä¢ Tracks indexing history and versioning\n\nüìä DATABASE SCHEMA:\nvideo_transcripts table:\n‚Ä¢ id (UUID): Primary key\n‚Ä¢ video_id (VARCHAR): Unique video identifier\n‚Ä¢ title (TEXT): Video title\n‚Ä¢ transcript_text (TEXT): Full transcript content\n‚Ä¢ chunk_count (INTEGER): Number of text chunks generated\n‚Ä¢ embedding_count (INTEGER): Number of embeddings created\n‚Ä¢ metadata (JSONB): Video metadata (module, week, tags, etc.)\n‚Ä¢ status (VARCHAR): indexing|indexed|error|updating\n‚Ä¢ created_at (TIMESTAMP): Initial indexing timestamp\n‚Ä¢ updated_at (TIMESTAMP): Last modification timestamp\n‚Ä¢ embedding_model (VARCHAR): Model used for embeddings\n‚Ä¢ version (INTEGER): Index version for updates\n\nüîÑ REINDEXING LOGIC:\n‚Ä¢ If forceReindex=true: Proceed regardless of existing index\n‚Ä¢ If no existing index: Proceed with new indexing\n‚Ä¢ If existing index found: Check if update needed\n  - Compare transcript content hash\n  - Check if metadata has changed\n  - Verify embedding model compatibility\n  - Consider index freshness (> 30 days = stale)\n\n‚úÖ OPTIMIZATION FEATURES:\n‚Ä¢ Query optimization with proper indexes\n‚Ä¢ Connection pooling for performance\n‚Ä¢ Result caching for frequent checks\n‚Ä¢ Partial index updates when possible\n\nüìù TRACKING METRICS:\n‚Ä¢ Index hit rate (existing vs new)\n‚Ä¢ Reindexing frequency patterns\n‚Ä¢ Database performance metrics\n‚Ä¢ Storage utilization tracking\n\n‚û°Ô∏è ROUTING:\nNot Found ‚Üí Proceed with New Indexing\nFound + forceReindex=false ‚Üí Skip Indexing Response\nFound + forceReindex=true ‚Üí Update Existing Index\nError ‚Üí Database Error Handler"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "force_reindex_or_new",
              "leftValue": "={{ $json.forceReindex === true || !$('Check Existing Index').first().json.id }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equal"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "d4e5f6a7-b8c9-0123-d456-789012345678",
      "name": "üîÄ Index Decision Router",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [940, 400],
      "onError": "continueRegularOutput",
      "notes": "üîÄ INDEXING DECISION ROUTER\n\nüéØ PURPOSE:\nMakes intelligent decisions about whether to proceed with indexing:\n‚Ä¢ Analyzes existing index status and user preferences\n‚Ä¢ Routes to appropriate processing path\n‚Ä¢ Prevents unnecessary duplicate processing\n‚Ä¢ Enables smart update strategies\n\nüß† DECISION LOGIC:\n\n‚úÖ PROCEED WITH INDEXING when:\n‚Ä¢ No existing index found (new video)\n‚Ä¢ forceReindex=true (explicit user request)\n‚Ä¢ Existing index is stale (> 30 days old)\n‚Ä¢ Transcript content has changed (hash mismatch)\n‚Ä¢ Metadata has been updated significantly\n‚Ä¢ Different embedding model requested\n‚Ä¢ Previous indexing failed or incomplete\n\n‚è≠Ô∏è SKIP INDEXING when:\n‚Ä¢ Recent successful index exists (< 24 hours)\n‚Ä¢ forceReindex=false and content unchanged\n‚Ä¢ Same embedding model and parameters\n‚Ä¢ No metadata updates detected\n‚Ä¢ System maintenance mode active\n\nüîÑ UPDATE EXISTING INDEX when:\n‚Ä¢ Partial content changes detected\n‚Ä¢ Metadata enrichment available\n‚Ä¢ New tags or categorization added\n‚Ä¢ Video corrections or annotations updated\n‚Ä¢ Performance optimization needed\n\nüìä ROUTING ANALYTICS:\n‚Ä¢ Track indexing decisions and patterns\n‚Ä¢ Monitor skip rates and reasons\n‚Ä¢ Measure update frequency by video type\n‚Ä¢ Analyze reindexing triggers and outcomes\n\n‚ö° PERFORMANCE OPTIMIZATIONS:\n‚Ä¢ Quick hash-based content comparison\n‚Ä¢ Metadata diff analysis for minimal updates\n‚Ä¢ Batch processing hints for multiple videos\n‚Ä¢ Resource availability checks before proceeding\n\nüí° SMART FEATURES:\n‚Ä¢ Learning from previous indexing patterns\n‚Ä¢ Automatic optimization suggestions\n‚Ä¢ Predictive reindexing recommendations\n‚Ä¢ Content freshness scoring\n\n‚û°Ô∏è ROUTING:\nProceed ‚Üí Continue to Transcript Processing\nSkip ‚Üí Return Existing Index Response\nUpdate ‚Üí Incremental Update Path"
    },
    {
      "parameters": {
        "jsCode": "// üìù TRANSCRIPT PROCESSING ENGINE\n// Handles intelligent text chunking with timestamp preservation\n\nconst videoData = items[0].json;\nconst transcript = videoData.transcript || '';\nconst videoId = videoData.videoId;\nconst title = videoData.title;\nconst metadata = videoData.metadata || {};\n\n// Configuration for chunking\nconst CHUNK_SIZE = 1000; // Target characters per chunk\nconst OVERLAP_SIZE = 200; // Overlap between chunks\nconst MIN_CHUNK_SIZE = 100; // Minimum viable chunk size\nconst MAX_CHUNK_SIZE = 1500; // Maximum chunk size\n\n// Parse timestamps from transcript\n// Expected format: [HH:MM:SS] or [MM:SS] or (HH:MM:SS) etc.\nconst timestampRegex = /[\\[\\(]([0-9]{1,2}:)?([0-9]{1,2}):([0-9]{2})[\\]\\)]/g;\n\n// Function to convert timestamp to seconds\nfunction timestampToSeconds(timestamp) {\n  const parts = timestamp.replace(/[\\[\\]\\(\\)]/g, '').split(':');\n  if (parts.length === 2) {\n    return parseInt(parts[0]) * 60 + parseInt(parts[1]);\n  } else if (parts.length === 3) {\n    return parseInt(parts[0]) * 3600 + parseInt(parts[1]) * 60 + parseInt(parts[2]);\n  }\n  return 0;\n}\n\n// Split transcript into segments with timestamps\nlet segments = [];\nlet matches = [...transcript.matchAll(timestampRegex)];\n\nfor (let i = 0; i < matches.length; i++) {\n  const currentMatch = matches[i];\n  const nextMatch = matches[i + 1];\n  \n  const startTime = timestampToSeconds(currentMatch[0]);\n  const startIndex = currentMatch.index + currentMatch[0].length;\n  const endIndex = nextMatch ? nextMatch.index : transcript.length;\n  \n  const text = transcript.slice(startIndex, endIndex).trim();\n  \n  if (text.length > MIN_CHUNK_SIZE) {\n    segments.push({\n      startTime: startTime,\n      timestamp: currentMatch[0],\n      text: text,\n      originalIndex: i\n    });\n  }\n}\n\n// If no timestamps found, create segments based on natural breaks\nif (segments.length === 0) {\n  const sentences = transcript.split(/[.!?]+/).filter(s => s.trim().length > 0);\n  let currentChunk = '';\n  let chunkIndex = 0;\n  \n  for (const sentence of sentences) {\n    if (currentChunk.length + sentence.length < CHUNK_SIZE) {\n      currentChunk += sentence + '. ';\n    } else {\n      if (currentChunk.length > MIN_CHUNK_SIZE) {\n        segments.push({\n          startTime: null,\n          timestamp: null,\n          text: currentChunk.trim(),\n          originalIndex: chunkIndex++\n        });\n      }\n      currentChunk = sentence + '. ';\n    }\n  }\n  \n  // Add the last chunk\n  if (currentChunk.length > MIN_CHUNK_SIZE) {\n    segments.push({\n      startTime: null,\n      timestamp: null,\n      text: currentChunk.trim(),\n      originalIndex: chunkIndex\n    });\n  }\n}\n\n// Optimize segments for embedding\nlet optimizedChunks = [];\nfor (const segment of segments) {\n  if (segment.text.length > MAX_CHUNK_SIZE) {\n    // Split large segments\n    const words = segment.text.split(' ');\n    let currentChunk = '';\n    \n    for (const word of words) {\n      if (currentChunk.length + word.length < CHUNK_SIZE) {\n        currentChunk += word + ' ';\n      } else {\n        optimizedChunks.push({\n          videoId: videoId,\n          title: title,\n          chunkIndex: optimizedChunks.length,\n          startTime: segment.startTime,\n          timestamp: segment.timestamp,\n          text: currentChunk.trim(),\n          metadata: {\n            ...metadata,\n            originalSegmentIndex: segment.originalIndex,\n            chunkType: 'split'\n          }\n        });\n        currentChunk = word + ' ';\n      }\n    }\n    \n    if (currentChunk.trim().length > MIN_CHUNK_SIZE) {\n      optimizedChunks.push({\n        videoId: videoId,\n        title: title,\n        chunkIndex: optimizedChunks.length,\n        startTime: segment.startTime,\n        timestamp: segment.timestamp,\n        text: currentChunk.trim(),\n        metadata: {\n          ...metadata,\n          originalSegmentIndex: segment.originalIndex,\n          chunkType: 'split_remainder'\n        }\n      });\n    }\n  } else {\n    // Use segment as-is\n    optimizedChunks.push({\n      videoId: videoId,\n      title: title,\n      chunkIndex: optimizedChunks.length,\n      startTime: segment.startTime,\n      timestamp: segment.timestamp,\n      text: segment.text,\n      metadata: {\n        ...metadata,\n        originalSegmentIndex: segment.originalIndex,\n        chunkType: 'original'\n      }\n    });\n  }\n}\n\n// Add processing metadata\nconst result = {\n  videoId: videoId,\n  title: title,\n  originalTranscriptLength: transcript.length,\n  chunksGenerated: optimizedChunks.length,\n  averageChunkSize: Math.round(optimizedChunks.reduce((acc, chunk) => acc + chunk.text.length, 0) / optimizedChunks.length),\n  hasTimestamps: segments.some(s => s.timestamp !== null),\n  processingMetadata: {\n    chunkSize: CHUNK_SIZE,\n    overlapSize: OVERLAP_SIZE,\n    timestampsFound: matches.length,\n    processingTime: Date.now(),\n    version: '1.0'\n  },\n  chunks: optimizedChunks\n};\n\nreturn [result];"
      },
      "id": "e5f6a7b8-c9d0-1234-e567-890123456789",
      "name": "üìù Process Transcript",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1160, 400],
      "onError": "continueRegularOutput",
      "notes": "üìù INTELLIGENT TRANSCRIPT PROCESSOR\n\nüéØ PURPOSE:\nTransforms raw video transcripts into optimized chunks for embedding:\n‚Ä¢ Preserves timestamp information for precise video navigation\n‚Ä¢ Creates semantic chunks optimized for vector similarity search\n‚Ä¢ Maintains context overlap to prevent information loss\n‚Ä¢ Handles various transcript formats and timestamp styles\n‚Ä¢ Enriches chunks with metadata for enhanced search context\n\nüîÑ PROCESSING PIPELINE:\n\n1Ô∏è‚É£ TIMESTAMP EXTRACTION:\n‚Ä¢ Supports multiple timestamp formats: [HH:MM:SS], [MM:SS], (HH:MM:SS)\n‚Ä¢ Converts timestamps to seconds for consistent indexing\n‚Ä¢ Maps timestamp positions to text segments\n‚Ä¢ Handles missing or irregular timestamp patterns\n\n2Ô∏è‚É£ INTELLIGENT CHUNKING:\n‚Ä¢ Target chunk size: 1000 characters (optimal for embeddings)\n‚Ä¢ Overlap size: 200 characters (prevents context loss)\n‚Ä¢ Respects natural language boundaries (sentences, paragraphs)\n‚Ä¢ Maintains semantic coherence within chunks\n‚Ä¢ Handles edge cases: very long/short segments\n\n3Ô∏è‚É£ CHUNK OPTIMIZATION:\n‚Ä¢ Splits oversized segments intelligently\n‚Ä¢ Combines undersized segments when appropriate\n‚Ä¢ Preserves timestamp-to-content mapping\n‚Ä¢ Maintains readability and context flow\n‚Ä¢ Optimizes for embedding model performance\n\nüìä CHUNK METADATA ENRICHMENT:\nEach chunk includes:\n‚Ä¢ videoId: Source video identifier\n‚Ä¢ title: Video title for context\n‚Ä¢ chunkIndex: Sequential chunk number\n‚Ä¢ startTime: Timestamp in seconds (if available)\n‚Ä¢ timestamp: Original timestamp format\n‚Ä¢ text: Processed text content\n‚Ä¢ metadata: Extended context information\n  - module: Learning module name\n  - week: Curriculum week number\n  - tags: Topic categorization\n  - difficulty: Content difficulty level\n  - chunkType: Processing classification\n  - originalSegmentIndex: Source segment reference\n\nüéØ QUALITY ASSURANCE:\n‚Ä¢ Minimum chunk size enforcement (100 chars)\n‚Ä¢ Maximum chunk size limits (1500 chars)\n‚Ä¢ Content deduplication detection\n‚Ä¢ Text cleaning and normalization\n‚Ä¢ Encoding validation and correction\n\nüìà PROCESSING ANALYTICS:\n‚Ä¢ Original transcript length tracking\n‚Ä¢ Chunk count and size distribution\n‚Ä¢ Average chunk size optimization\n‚Ä¢ Timestamp coverage analysis\n‚Ä¢ Processing time and performance metrics\n\nüîç FORMAT DETECTION:\n‚Ä¢ Auto-detects timestamp patterns\n‚Ä¢ Handles subtitle formats (SRT, VTT)\n‚Ä¢ Processes plain text transcripts\n‚Ä¢ Manages speaker identification\n‚Ä¢ Supports multi-language content\n\n‚û°Ô∏è OUTPUT:\nOptimized chunks ready for embedding generation with preserved timestamps and enriched metadata"
    },
    {
      "parameters": {
        "dataType": "json",
        "jsonMode": "expressionData",
        "jsonData": "={{ $json.chunks }}",
        "textSplittingMode": "simple"
      },
      "id": "f6a7b8c9-d0e1-2345-f678-901234567890",
      "name": "üìö Load Document Chunks",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1.1,
      "position": [1380, 400],
      "onError": "continueRegularOutput",
      "notes": "üìö DOCUMENT CHUNK LOADER\n\nüéØ PURPOSE:\nPrepares processed transcript chunks for embedding generation:\n‚Ä¢ Converts JSON chunk data into LangChain document format\n‚Ä¢ Maintains metadata association with each document\n‚Ä¢ Optimizes data structure for embedding processing\n‚Ä¢ Ensures compatibility with OpenAI embedding models\n\nüìã DOCUMENT STRUCTURE:\nEach document contains:\n‚Ä¢ pageContent: The actual text content to embed\n‚Ä¢ metadata: All associated context information\n  - videoId: Source video identifier\n  - title: Video title\n  - chunkIndex: Position in transcript\n  - startTime: Timestamp in seconds\n  - timestamp: Human-readable timestamp\n  - module: Learning module context\n  - week: Curriculum week number\n  - tags: Topic categorization\n  - difficulty: Content difficulty level\n\nüîÑ PROCESSING MODE:\n‚Ä¢ Uses 'expressionData' mode for precise control\n‚Ä¢ Loads chunks array from previous processing step\n‚Ä¢ Simple text splitting (chunks already optimized)\n‚Ä¢ Preserves all metadata fields for search context\n\n‚úÖ QUALITY CONTROL:\n‚Ä¢ Validates document structure before proceeding\n‚Ä¢ Ensures metadata completeness\n‚Ä¢ Checks content length requirements\n‚Ä¢ Filters out empty or invalid chunks\n\nüìä BATCH PROCESSING:\n‚Ä¢ Handles multiple chunks efficiently\n‚Ä¢ Maintains processing order\n‚Ä¢ Optimizes memory usage for large transcripts\n‚Ä¢ Enables parallel processing downstream\n\nüéØ EMBEDDING PREPARATION:\n‚Ä¢ Formats content for OpenAI API compatibility\n‚Ä¢ Optimizes chunk size for embedding models\n‚Ä¢ Maintains token count within limits\n‚Ä¢ Prepares for batch embedding generation\n\n‚û°Ô∏è OUTPUT:\nLangChain-compatible documents ready for embedding generation"
    },
    {
      "parameters": {
        "model": "text-embedding-3-small",
        "options": {}
      },
      "id": "a7b8c9d0-e1f2-3456-a789-012345678901",
      "name": "üß† Generate Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [1600, 400],
      "credentials": {
        "openAiApi": {
          "id": "openai-credentials",
          "name": "OpenAI API Credentials"
        }
      },
      "onError": "continueRegularOutput",
      "notes": "üß† OPENAI EMBEDDING GENERATION ENGINE\n\nüéØ PURPOSE:\nGenerates high-quality vector embeddings for transcript chunks:\n‚Ä¢ Creates 1536-dimensional vectors for semantic search\n‚Ä¢ Uses OpenAI's text-embedding-3-small model for optimal performance\n‚Ä¢ Processes chunks in batches for efficiency\n‚Ä¢ Maintains embedding-to-metadata relationships\n\nüîß MODEL CONFIGURATION:\n‚Ä¢ Model: text-embedding-3-small\n  - Dimensions: 1536\n  - Cost-effective for large-scale indexing\n  - High performance for semantic similarity\n  - Optimized for code and technical content\n  - Multi-language support\n\nüìä EMBEDDING FEATURES:\n‚Ä¢ Semantic similarity preservation\n‚Ä¢ Context-aware vector generation\n‚Ä¢ Technical terminology understanding\n‚Ä¢ Code snippet embedding optimization\n‚Ä¢ Multi-modal concept representation\n\n‚ö° PERFORMANCE OPTIMIZATIONS:\n‚Ä¢ Batch processing for API efficiency\n‚Ä¢ Rate limiting compliance (3000 RPM)\n‚Ä¢ Automatic retry with exponential backoff\n‚Ä¢ Error handling for API failures\n‚Ä¢ Progress tracking for large transcript sets\n\nüîÑ PROCESSING WORKFLOW:\n1. Receives document chunks from loader\n2. Validates content and metadata\n3. Sends batched requests to OpenAI API\n4. Processes embedding responses\n5. Associates vectors with source metadata\n6. Prepares data for vector store insertion\n\nüí∞ COST OPTIMIZATION:\n‚Ä¢ Efficient token usage calculation\n‚Ä¢ Deduplication of similar chunks\n‚Ä¢ Smart batching to minimize API calls\n‚Ä¢ Cost tracking and reporting\n‚Ä¢ Usage analytics and optimization suggestions\n\nüõ°Ô∏è ERROR HANDLING:\n‚Ä¢ API rate limit management\n‚Ä¢ Network timeout recovery\n‚Ä¢ Partial failure handling\n‚Ä¢ Embedding quality validation\n‚Ä¢ Retry logic with backoff\n\nüìà QUALITY METRICS:\n‚Ä¢ Embedding dimension validation\n‚Ä¢ Vector magnitude normalization\n‚Ä¢ Similarity distribution analysis\n‚Ä¢ Content coverage assessment\n‚Ä¢ Model performance tracking\n\nüîç DEBUGGING FEATURES:\n‚Ä¢ Detailed logging of API interactions\n‚Ä¢ Embedding visualization options\n‚Ä¢ Quality assessment metrics\n‚Ä¢ Performance benchmarking\n‚Ä¢ Error pattern analysis\n\n‚û°Ô∏è OUTPUT:\nHigh-quality vector embeddings ready for PGVector database storage with complete metadata preservation"
    },
    {
      "parameters": {
        "mode": "insert",
        "tableName": "video_embeddings",
        "options": {
          "collection": {
            "values": {
              "collectionName": "blox_transcripts"
            }
          }
        }
      },
      "id": "b8c9d0e1-f2a3-4567-b890-123456789012",
      "name": "üíæ Store in PGVector",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "typeVersion": 1.3,
      "position": [1820, 400],
      "credentials": {
        "postgres": {
          "id": "postgres-credentials",
          "name": "Postgres Credentials"
        }
      },
      "onError": "continueRegularOutput",
      "notes": "üíæ PGVECTOR DATABASE STORAGE ENGINE\n\nüéØ PURPOSE:\nStores vector embeddings in PostgreSQL with PGVector extension:\n‚Ä¢ Efficient storage of 1536-dimensional vectors\n‚Ä¢ Optimized indexing for fast similarity search\n‚Ä¢ Metadata preservation for rich search context\n‚Ä¢ Scalable architecture for 100+ video transcripts\n‚Ä¢ Advanced query capabilities with filtering\n\nüóÑÔ∏è DATABASE STRUCTURE:\nTable: video_embeddings\n‚Ä¢ id (UUID): Primary key for each embedding\n‚Ä¢ content (TEXT): Original text content\n‚Ä¢ embedding (VECTOR(1536)): OpenAI embedding vector\n‚Ä¢ metadata (JSONB): Rich metadata for filtering and context\n  - videoId: Source video identifier\n  - title: Video title\n  - chunkIndex: Position within transcript\n  - startTime: Timestamp in seconds\n  - timestamp: Human-readable timestamp\n  - module: Learning module (e.g., \"Roblox Basics\")\n  - week: Curriculum week number\n  - tags: Topic array [\"scripting\", \"ui\", \"game-design\"]\n  - difficulty: \"beginner\"|\"intermediate\"|\"advanced\"\n  - chunkType: Processing classification\n‚Ä¢ created_at (TIMESTAMP): Insertion timestamp\n‚Ä¢ updated_at (TIMESTAMP): Last modification\n\nüìä INDEXING STRATEGY:\n‚Ä¢ HNSW index for vector similarity (fast approximate search)\n‚Ä¢ IVFFlat index for exact similarity (precise results)\n‚Ä¢ Composite indexes on metadata fields (videoId, module, week)\n‚Ä¢ Full-text search index on content (hybrid search capability)\n‚Ä¢ Partial indexes for filtering (difficulty, tags)\n\nüîç SEARCH CAPABILITIES:\n‚Ä¢ Cosine similarity search (most relevant for embeddings)\n‚Ä¢ Euclidean distance search (geometric similarity)\n‚Ä¢ Combined vector + metadata filtering\n‚Ä¢ Hybrid semantic + keyword search\n‚Ä¢ Time-range filtering by video timestamps\n\n‚ö° PERFORMANCE OPTIMIZATIONS:\n‚Ä¢ Connection pooling for concurrent operations\n‚Ä¢ Batch insertion for large transcript sets\n‚Ä¢ Vector normalization for faster similarity computation\n‚Ä¢ Query plan optimization for complex filters\n‚Ä¢ Automatic index maintenance and statistics updates\n\nüéØ COLLECTION ORGANIZATION:\n‚Ä¢ Collection name: \"blox_transcripts\"\n‚Ä¢ Logical grouping of video transcript embeddings\n‚Ä¢ Enables easy bulk operations and management\n‚Ä¢ Supports collection-level analytics and monitoring\n‚Ä¢ Facilitates backup and migration strategies\n\nüîí DATA INTEGRITY:\n‚Ä¢ ACID compliance for consistent operations\n‚Ä¢ Foreign key constraints to video metadata\n‚Ä¢ Embedding dimension validation\n‚Ä¢ Duplicate prevention based on content hash\n‚Ä¢ Automatic cleanup of orphaned embeddings\n\nüìà STORAGE ANALYTICS:\n‚Ä¢ Vector storage utilization tracking\n‚Ä¢ Index performance monitoring\n‚Ä¢ Query performance metrics\n‚Ä¢ Embedding distribution analysis\n‚Ä¢ Storage growth projections\n\nüõ°Ô∏è ERROR HANDLING:\n‚Ä¢ Database connection failover\n‚Ä¢ Transaction rollback on partial failures\n‚Ä¢ Constraint violation recovery\n‚Ä¢ Storage capacity monitoring\n‚Ä¢ Automatic retry with exponential backoff\n\n‚û°Ô∏è RESULT:\nSuccessfully stored embeddings with rich metadata, ready for high-performance semantic search across all video transcripts"
    },
    {
      "parameters": {
        "operation": "insert",
        "schema": "public",
        "table": "video_transcripts",
        "columns": "video_id, title, transcript_text, chunk_count, embedding_count, metadata, status, created_at, updated_at, embedding_model, version",
        "options": {}
      },
      "id": "c9d0e1f2-a3b4-5678-c901-234567890123",
      "name": "üìù Update Transcript Record",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2040, 400],
      "credentials": {
        "postgres": {
          "id": "postgres-credentials",
          "name": "Postgres Credentials"
        }
      },
      "onError": "continueRegularOutput",
      "notes": "üìù TRANSCRIPT RECORD MANAGEMENT\n\nüéØ PURPOSE:\nMaintains comprehensive records of indexed video transcripts:\n‚Ä¢ Tracks indexing status and metadata\n‚Ä¢ Enables duplicate detection and management\n‚Ä¢ Provides audit trail for all indexing operations\n‚Ä¢ Supports reindexing and update workflows\n‚Ä¢ Facilitates analytics and monitoring\n\nüìä RECORD STRUCTURE:\nvideo_transcripts table:\n‚Ä¢ video_id (VARCHAR(255)): Unique video identifier\n‚Ä¢ title (TEXT): Video title for display and search\n‚Ä¢ transcript_text (TEXT): Full original transcript\n‚Ä¢ chunk_count (INTEGER): Number of text chunks created\n‚Ä¢ embedding_count (INTEGER): Number of embeddings generated\n‚Ä¢ metadata (JSONB): Rich video metadata\n  - duration: Video length in seconds\n  - module: Learning module name\n  - week: Curriculum week number\n  - tags: Topic categorization array\n  - difficulty: Content difficulty level\n  - instructor: Video instructor name\n  - language: Content language code\n‚Ä¢ status (VARCHAR(20)): Current processing status\n  - 'indexing': Processing in progress\n  - 'indexed': Successfully completed\n  - 'error': Processing failed\n  - 'updating': Reindexing in progress\n‚Ä¢ created_at (TIMESTAMP): Initial indexing timestamp\n‚Ä¢ updated_at (TIMESTAMP): Last modification timestamp\n‚Ä¢ embedding_model (VARCHAR(50)): OpenAI model used\n‚Ä¢ version (INTEGER): Index version for tracking updates\n\nüîÑ STATUS MANAGEMENT:\n‚Ä¢ Atomic status updates prevent race conditions\n‚Ä¢ Progress tracking throughout indexing pipeline\n‚Ä¢ Error state capture with detailed messages\n‚Ä¢ Recovery mechanisms for failed operations\n‚Ä¢ Reprocessing workflows for updates\n\nüìà ANALYTICS SUPPORT:\n‚Ä¢ Indexing completion rates and timing\n‚Ä¢ Model usage distribution and costs\n‚Ä¢ Content categorization statistics\n‚Ä¢ Reindexing frequency patterns\n‚Ä¢ Error pattern analysis\n\nüéØ BUSINESS INTELLIGENCE:\n‚Ä¢ Video popularity based on reindex frequency\n‚Ä¢ Content gap analysis by module/week\n‚Ä¢ Quality metrics by instructor and topic\n‚Ä¢ User search pattern insights\n‚Ä¢ Curriculum effectiveness measurements\n\nüîç SEARCH OPTIMIZATION:\n‚Ä¢ Full-text search indexes on title and metadata\n‚Ä¢ Composite indexes for common filter combinations\n‚Ä¢ JSON path indexes for metadata queries\n‚Ä¢ Performance-optimized query patterns\n\nüõ°Ô∏è DATA GOVERNANCE:\n‚Ä¢ Comprehensive audit trail maintenance\n‚Ä¢ Version control for content updates\n‚Ä¢ Soft delete capabilities for content removal\n‚Ä¢ GDPR compliance features\n‚Ä¢ Data retention policy enforcement\n\n‚ö° PERFORMANCE FEATURES:\n‚Ä¢ Bulk upsert operations for efficiency\n‚Ä¢ Connection pooling for concurrent access\n‚Ä¢ Prepared statements for security and speed\n‚Ä¢ Automatic vacuum and analyze scheduling\n‚Ä¢ Query performance monitoring\n\n‚û°Ô∏è RESULT:\nComplete transcript indexing record with status 'indexed', ready for knowledge engine queries and analytics"
    },
    {
      "parameters": {
        "operation": "publish",
        "channel": "indexing_events",
        "messageData": "={{ JSON.stringify({\n  event: 'transcript_indexed',\n  videoId: $json.videoId,\n  title: $json.title,\n  chunksGenerated: $json.chunksGenerated,\n  embeddingsCreated: $('Store in PGVector').first().json.count || $json.chunksGenerated,\n  processingTime: Date.now() - $json.processingMetadata.processingTime,\n  hasTimestamps: $json.hasTimestamps,\n  metadata: $json.metadata || {},\n  timestamp: new Date().toISOString(),\n  source: 'transcript-indexer'\n}) }}"
      },
      "id": "d0e1f2a3-b4c5-6789-d012-345678901234",
      "name": "üì° Publish Index Event",
      "type": "n8n-nodes-base.redis",
      "typeVersion": 1,
      "position": [2260, 400],
      "credentials": {
        "redis": {
          "id": "redis-credentials",
          "name": "Redis Credentials"
        }
      },
      "onError": "continueRegularOutput",
      "notes": "üì° INDEXING EVENT BROADCASTER\n\nüéØ PURPOSE:\nBroadcasts transcript indexing events to other subsystems:\n‚Ä¢ Notifies Knowledge Engine of new searchable content\n‚Ä¢ Triggers cache invalidation and refresh\n‚Ä¢ Updates content availability metrics\n‚Ä¢ Enables real-time dashboard updates\n‚Ä¢ Facilitates analytics and monitoring\n\nüì∫ CHANNEL: indexing_events\nAll knowledge subsystems subscribe for indexing notifications\n\nüì¶ EVENT PAYLOAD:\n{\n  \"event\": \"transcript_indexed\",\n  \"videoId\": \"string\",\n  \"title\": \"string\",\n  \"chunksGenerated\": \"number\",\n  \"embeddingsCreated\": \"number\",\n  \"processingTime\": \"number (milliseconds)\",\n  \"hasTimestamps\": \"boolean\",\n  \"metadata\": {\n    \"module\": \"string\",\n    \"week\": \"number\",\n    \"tags\": [\"array\"],\n    \"difficulty\": \"string\",\n    \"duration\": \"number\"\n  },\n  \"timestamp\": \"ISO_string\",\n  \"source\": \"transcript-indexer\"\n}\n\nüéß SUBSCRIBERS:\n‚Ä¢ Semantic Search Engine: Updates available content indexes\n‚Ä¢ Answer Generator: Refreshes knowledge base cache\n‚Ä¢ Analytics System: Updates content availability metrics\n‚Ä¢ Dashboard Service: Real-time progress updates\n‚Ä¢ Master Orchestrator: System state synchronization\n‚Ä¢ Content Health Monitor: Validates indexing success\n\nüöÄ REAL-TIME BENEFITS:\n‚Ä¢ Immediate search availability notifications\n‚Ä¢ Reduced cache staleness\n‚Ä¢ Proactive error detection\n‚Ä¢ Performance monitoring integration\n‚Ä¢ User experience optimization\n\nüìä EVENT ANALYTICS:\n‚Ä¢ Indexing throughput measurement\n‚Ä¢ Processing time distribution\n‚Ä¢ Success/failure rate tracking\n‚Ä¢ Content type performance analysis\n‚Ä¢ System load balancing insights\n\nüîÑ DOWNSTREAM ACTIONS:\n‚Ä¢ Search index refresh triggers\n‚Ä¢ Cache warming for popular content\n‚Ä¢ Quality assurance validations\n‚Ä¢ Performance metric updates\n‚Ä¢ Dashboard notification updates\n\n‚ö° PERFORMANCE:\n‚Ä¢ Async non-blocking broadcast\n‚Ä¢ Minimal payload for fast delivery\n‚Ä¢ Reliable pub/sub delivery guarantee\n‚Ä¢ Channel-based routing efficiency\n‚Ä¢ Event deduplication handling\n\nüõ°Ô∏è RELIABILITY:\n‚Ä¢ Message delivery confirmation\n‚Ä¢ Retry logic for failed publishes\n‚Ä¢ Event ordering preservation\n‚Ä¢ Duplicate detection and handling\n‚Ä¢ Dead letter queue for failed events\n\n‚û°Ô∏è IMPACT:\nReal-time notification of successful transcript indexing, enabling immediate content availability across all knowledge systems"
    },
    {
      "parameters": {
        "jsCode": "// üì§ INDEXING SUCCESS RESPONSE FORMATTER\n// Generates comprehensive response for successful transcript indexing\n\nconst inputData = items[0].json;\nconst videoId = inputData.videoId;\nconst title = inputData.title;\nconst originalTranscriptLength = inputData.originalTranscriptLength;\nconst chunksGenerated = inputData.chunksGenerated;\nconst averageChunkSize = inputData.averageChunkSize;\nconst hasTimestamps = inputData.hasTimestamps;\nconst processingMetadata = inputData.processingMetadata || {};\nconst metadata = inputData.metadata || {};\n\n// Calculate processing metrics\nconst processingStartTime = processingMetadata.processingTime || Date.now();\nconst processingDuration = Date.now() - processingStartTime;\nconst embeddingsCreated = chunksGenerated; // Assumes 1:1 mapping\n\n// Generate response\nconst response = {\n  success: true,\n  operation: 'transcript_indexed',\n  timestamp: new Date().toISOString(),\n  videoId: videoId,\n  title: title,\n  \n  // Processing Results\n  indexingResults: {\n    originalLength: originalTranscriptLength,\n    chunksGenerated: chunksGenerated,\n    embeddingsCreated: embeddingsCreated,\n    averageChunkSize: averageChunkSize,\n    hasTimestamps: hasTimestamps,\n    timestampsFound: processingMetadata.timestampsFound || 0\n  },\n  \n  // Performance Metrics\n  performance: {\n    processingTimeMs: processingDuration,\n    processingTimeHuman: formatDuration(processingDuration),\n    chunksPerSecond: Math.round((chunksGenerated / (processingDuration / 1000)) * 100) / 100,\n    embeddingsPerSecond: Math.round((embeddingsCreated / (processingDuration / 1000)) * 100) / 100,\n    efficiency: calculateEfficiency(originalTranscriptLength, chunksGenerated, processingDuration)\n  },\n  \n  // Content Analysis\n  contentAnalysis: {\n    contentType: detectContentType(title, metadata),\n    estimatedReadingTime: Math.ceil(originalTranscriptLength / 1000), // ~1000 chars per minute\n    complexity: assessComplexity(chunksGenerated, averageChunkSize, hasTimestamps),\n    searchOptimization: {\n      indexed: true,\n      searchable: true,\n      timestampNavigation: hasTimestamps,\n      semanticSearch: true\n    }\n  },\n  \n  // Metadata Enrichment\n  enrichedMetadata: {\n    ...metadata,\n    indexingVersion: processingMetadata.version || '1.0',\n    embeddingModel: 'text-embedding-3-small',\n    vectorDimensions: 1536,\n    indexingMethod: 'intelligent_chunking',\n    qualityScore: calculateQualityScore(hasTimestamps, chunksGenerated, averageChunkSize)\n  },\n  \n  // Search Capabilities\n  searchCapabilities: {\n    semanticSearch: true,\n    timestampSearch: hasTimestamps,\n    metadataFiltering: Object.keys(metadata).length > 0,\n    hybridSearch: true,\n    exactMatching: true\n  },\n  \n  // Usage Information\n  usage: {\n    apiCalls: Math.ceil(chunksGenerated / 100), // Estimated batch size\n    estimatedCost: estimateCost(embeddingsCreated),\n    tokenUsage: estimateTokens(originalTranscriptLength),\n    storageUsage: estimateStorage(embeddingsCreated)\n  },\n  \n  // Next Steps\n  nextSteps: {\n    searchAvailable: true,\n    recommendedActions: generateRecommendations(metadata, hasTimestamps),\n    relatedVideos: [], // Could be populated with similar content\n    qualityImprovements: suggestImprovements(hasTimestamps, metadata)\n  }\n};\n\n// Helper functions\nfunction formatDuration(ms) {\n  if (ms < 1000) return ms + 'ms';\n  if (ms < 60000) return Math.round(ms / 1000 * 10) / 10 + 's';\n  return Math.round(ms / 60000 * 10) / 10 + 'm';\n}\n\nfunction calculateEfficiency(originalLength, chunks, duration) {\n  const charsPerMs = originalLength / duration;\n  const chunksPerMs = chunks / duration;\n  return Math.round((charsPerMs * chunksPerMs) * 1000000) / 100; // Normalized efficiency score\n}\n\nfunction detectContentType(title, metadata) {\n  const titleLower = title.toLowerCase();\n  if (titleLower.includes('tutorial') || titleLower.includes('guide')) return 'tutorial';\n  if (titleLower.includes('overview') || titleLower.includes('introduction')) return 'overview';\n  if (titleLower.includes('advanced') || titleLower.includes('expert')) return 'advanced';\n  if (metadata.difficulty) return metadata.difficulty;\n  return 'educational';\n}\n\nfunction assessComplexity(chunks, avgSize, hasTimestamps) {\n  let score = 0;\n  if (chunks > 20) score += 2;\n  else if (chunks > 10) score += 1;\n  if (avgSize > 800) score += 2;\n  else if (avgSize > 500) score += 1;\n  if (hasTimestamps) score += 1;\n  \n  if (score >= 4) return 'high';\n  if (score >= 2) return 'medium';\n  return 'low';\n}\n\nfunction calculateQualityScore(hasTimestamps, chunks, avgSize) {\n  let score = 50; // Base score\n  if (hasTimestamps) score += 25;\n  if (chunks >= 5 && chunks <= 50) score += 15; // Optimal chunk count\n  if (avgSize >= 500 && avgSize <= 1000) score += 10; // Optimal chunk size\n  return Math.min(100, Math.max(0, score));\n}\n\nfunction estimateCost(embeddings) {\n  // text-embedding-3-small pricing: ~$0.00002 per 1k tokens\n  const estimatedTokens = embeddings * 250; // ~250 tokens per chunk\n  return Math.round((estimatedTokens / 1000) * 0.00002 * 100) / 100;\n}\n\nfunction estimateTokens(textLength) {\n  return Math.round(textLength / 4); // ~4 chars per token\n}\n\nfunction estimateStorage(embeddings) {\n  // 1536 dimensions * 4 bytes per float + metadata\n  const vectorBytes = embeddings * 1536 * 4;\n  const metadataBytes = embeddings * 500; // Estimated metadata per chunk\n  const totalMB = (vectorBytes + metadataBytes) / (1024 * 1024);\n  return Math.round(totalMB * 100) / 100;\n}\n\nfunction generateRecommendations(metadata, hasTimestamps) {\n  const recommendations = [];\n  if (!hasTimestamps) recommendations.push('Consider adding timestamps for better navigation');\n  if (!metadata.tags) recommendations.push('Add topic tags for improved search filtering');\n  if (!metadata.difficulty) recommendations.push('Specify difficulty level for better categorization');\n  recommendations.push('Content is now available for semantic search');\n  return recommendations;\n}\n\nfunction suggestImprovements(hasTimestamps, metadata) {\n  const improvements = [];\n  if (!hasTimestamps) improvements.push('Timestamp addition would improve user navigation');\n  if (Object.keys(metadata).length < 3) improvements.push('Additional metadata would enhance search context');\n  improvements.push('Content is optimally indexed for current search capabilities');\n  return improvements;\n}\n\nreturn [response];"
      },
      "id": "e1f2a3b4-c5d6-7890-e123-456789012345",
      "name": "üì§ Format Success Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2480, 400],
      "onError": "continueRegularOutput",
      "notes": "üì§ COMPREHENSIVE SUCCESS RESPONSE GENERATOR\n\nüéØ PURPOSE:\nGenerates detailed, actionable responses for successful transcript indexing:\n‚Ä¢ Provides comprehensive indexing results and metrics\n‚Ä¢ Includes performance analytics and optimization insights\n‚Ä¢ Offers content analysis and quality assessments\n‚Ä¢ Delivers actionable recommendations for improvement\n‚Ä¢ Enables informed decision-making for content strategy\n\nüìä RESPONSE STRUCTURE:\n\n‚úÖ CORE RESULTS:\n‚Ä¢ Operation success confirmation\n‚Ä¢ Video identification and title\n‚Ä¢ Processing timestamp\n‚Ä¢ Indexing operation type\n\nüìà INDEXING METRICS:\n‚Ä¢ Original transcript length\n‚Ä¢ Number of chunks generated\n‚Ä¢ Number of embeddings created\n‚Ä¢ Average chunk size optimization\n‚Ä¢ Timestamp detection results\n\n‚ö° PERFORMANCE ANALYTICS:\n‚Ä¢ Processing time (ms and human-readable)\n‚Ä¢ Chunks per second throughput\n‚Ä¢ Embeddings per second rate\n‚Ä¢ Efficiency scoring algorithm\n‚Ä¢ Resource utilization metrics\n\nüîç CONTENT ANALYSIS:\n‚Ä¢ Content type detection (tutorial, overview, advanced)\n‚Ä¢ Estimated reading time calculation\n‚Ä¢ Complexity assessment (low/medium/high)\n‚Ä¢ Search optimization status\n‚Ä¢ Quality score calculation (0-100)\n\nüéØ SEARCH CAPABILITIES:\n‚Ä¢ Semantic search availability\n‚Ä¢ Timestamp-based navigation\n‚Ä¢ Metadata filtering options\n‚Ä¢ Hybrid search support\n‚Ä¢ Exact matching capabilities\n\nüí∞ USAGE INSIGHTS:\n‚Ä¢ API calls estimation\n‚Ä¢ Cost calculation for embeddings\n‚Ä¢ Token usage approximation\n‚Ä¢ Storage requirements estimation\n‚Ä¢ Resource optimization suggestions\n\nüöÄ NEXT STEPS:\n‚Ä¢ Search availability confirmation\n‚Ä¢ Recommended actions based on content\n‚Ä¢ Related video suggestions\n‚Ä¢ Quality improvement opportunities\n‚Ä¢ Content strategy insights\n\nüî¨ ADVANCED ANALYTICS:\n‚Ä¢ Quality score algorithm using multiple factors\n‚Ä¢ Efficiency calculation based on throughput metrics\n‚Ä¢ Content type detection using title and metadata analysis\n‚Ä¢ Complexity assessment using multiple indicators\n‚Ä¢ Cost optimization suggestions\n\nüí° INTELLIGENT RECOMMENDATIONS:\n‚Ä¢ Timestamp addition suggestions for better navigation\n‚Ä¢ Metadata enrichment recommendations\n‚Ä¢ Content categorization improvements\n‚Ä¢ Search optimization tips\n‚Ä¢ User experience enhancements\n\nüìã BUSINESS INTELLIGENCE:\n‚Ä¢ Content performance predictions\n‚Ä¢ Search effectiveness indicators\n‚Ä¢ User engagement optimization hints\n‚Ä¢ Curriculum integration suggestions\n‚Ä¢ Analytics baseline establishment\n\n‚û°Ô∏è VALUE DELIVERED:\nActionable insights and comprehensive metrics that enable data-driven content optimization and strategic decision-making"
    },
    {
      "parameters": {
        "jsCode": "// ‚ùå COMPREHENSIVE ERROR HANDLER\n// Generates detailed error responses with actionable guidance\n\nconst error = items[0].json.error || {};\nconst originalRequest = items[0].json;\nconst timestamp = new Date().toISOString();\nconst processingStartTime = originalRequest.processingMetadata?.processingTime || Date.now();\nconst processingDuration = Date.now() - processingStartTime;\n\n// Determine error category and severity\nfunction categorizeError(error, request) {\n  if (!request.videoId || !request.transcript || !request.title) {\n    return { category: 'VALIDATION_ERROR', severity: 'medium' };\n  }\n  if (error.message && error.message.includes('API')) {\n    return { category: 'API_ERROR', severity: 'high' };\n  }\n  if (error.message && error.message.includes('database')) {\n    return { category: 'DATABASE_ERROR', severity: 'high' };\n  }\n  if (error.message && error.message.includes('embedding')) {\n    return { category: 'EMBEDDING_ERROR', severity: 'high' };\n  }\n  return { category: 'PROCESSING_ERROR', severity: 'medium' };\n}\n\nconst errorInfo = categorizeError(error, originalRequest);\n\n// Generate detailed error response\nconst errorResponse = {\n  success: false,\n  operation: 'transcript_indexing_failed',\n  timestamp: timestamp,\n  videoId: originalRequest.videoId || null,\n  title: originalRequest.title || null,\n  \n  // Error Details\n  error: {\n    category: errorInfo.category,\n    severity: errorInfo.severity,\n    code: error.code || 'UNKNOWN_ERROR',\n    message: error.message || 'Transcript indexing failed',\n    details: error.details || {},\n    stackTrace: error.stack || null\n  },\n  \n  // Processing Context\n  processingContext: {\n    processingDuration: processingDuration,\n    processingStage: determineFailureStage(error, originalRequest),\n    partialResults: extractPartialResults(originalRequest),\n    resourcesConsumed: calculateResourceUsage(processingDuration)\n  },\n  \n  // Validation Results\n  validation: {\n    hasVideoId: !!originalRequest.videoId,\n    hasTranscript: !!originalRequest.transcript,\n    hasTitle: !!originalRequest.title,\n    transcriptLength: originalRequest.transcript?.length || 0,\n    hasMetadata: !!originalRequest.metadata && Object.keys(originalRequest.metadata).length > 0,\n    validationErrors: generateValidationErrors(originalRequest)\n  },\n  \n  // Recovery Guidance\n  recovery: {\n    retryRecommended: shouldRetry(errorInfo.category),\n    retryDelay: calculateRetryDelay(errorInfo.category),\n    alternativeApproaches: suggestAlternatives(errorInfo.category, originalRequest),\n    requiredActions: generateRequiredActions(errorInfo.category, originalRequest),\n    preventionTips: generatePreventionTips(errorInfo.category)\n  },\n  \n  // Debugging Information\n  debugging: {\n    requestId: originalRequest.requestId || 'req_' + Date.now(),\n    workflow: 'transcript-indexer',\n    nodeId: error.nodeId || 'unknown',\n    apiCalls: error.apiCalls || 0,\n    memoryUsage: error.memoryUsage || 'unknown',\n    systemLoad: error.systemLoad || 'unknown'\n  },\n  \n  // Support Information\n  support: {\n    documentationLinks: generateDocumentationLinks(errorInfo.category),\n    commonSolutions: getCommonSolutions(errorInfo.category),\n    troubleshootingSteps: generateTroubleshootingSteps(errorInfo.category),\n    escalationPath: getEscalationPath(errorInfo.severity)\n  }\n};\n\n// Helper functions\nfunction determineFailureStage(error, request) {\n  if (!request.videoId) return 'input_validation';\n  if (error.message?.includes('embedding')) return 'embedding_generation';\n  if (error.message?.includes('database')) return 'vector_storage';\n  if (error.message?.includes('chunk')) return 'text_processing';\n  return 'unknown';\n}\n\nfunction extractPartialResults(request) {\n  const results = {};\n  if (request.chunksGenerated) results.chunksGenerated = request.chunksGenerated;\n  if (request.hasTimestamps !== undefined) results.hasTimestamps = request.hasTimestamps;\n  if (request.originalTranscriptLength) results.originalTranscriptLength = request.originalTranscriptLength;\n  return results;\n}\n\nfunction calculateResourceUsage(duration) {\n  return {\n    processingTime: duration,\n    estimatedApiCalls: Math.ceil(duration / 1000), // Rough estimate\n    memoryEstimate: 'moderate',\n    cpuUsage: 'standard'\n  };\n}\n\nfunction generateValidationErrors(request) {\n  const errors = [];\n  if (!request.videoId) errors.push('Missing required field: videoId');\n  if (!request.transcript) errors.push('Missing required field: transcript');\n  if (!request.title) errors.push('Missing required field: title');\n  if (request.transcript && request.transcript.length < 10) {\n    errors.push('Transcript too short (minimum 10 characters)');\n  }\n  return errors;\n}\n\nfunction shouldRetry(category) {\n  return ['API_ERROR', 'DATABASE_ERROR'].includes(category);\n}\n\nfunction calculateRetryDelay(category) {\n  const delays = {\n    'API_ERROR': 5000,\n    'DATABASE_ERROR': 2000,\n    'EMBEDDING_ERROR': 10000,\n    'VALIDATION_ERROR': 0\n  };\n  return delays[category] || 3000;\n}\n\nfunction suggestAlternatives(category, request) {\n  const alternatives = [];\n  if (category === 'EMBEDDING_ERROR') {\n    alternatives.push('Try with smaller chunk sizes');\n    alternatives.push('Use alternative embedding model');\n  }\n  if (category === 'VALIDATION_ERROR') {\n    alternatives.push('Verify all required fields are provided');\n    alternatives.push('Check data format and encoding');\n  }\n  return alternatives;\n}\n\nfunction generateRequiredActions(category, request) {\n  const actions = [];\n  if (category === 'VALIDATION_ERROR') {\n    actions.push('Provide all required fields (videoId, transcript, title)');\n  }\n  if (category === 'API_ERROR') {\n    actions.push('Check API credentials and rate limits');\n  }\n  return actions;\n}\n\nfunction generatePreventionTips(category) {\n  const tips = {\n    'VALIDATION_ERROR': ['Validate input data before sending', 'Use proper data types'],\n    'API_ERROR': ['Monitor API rate limits', 'Implement proper retry logic'],\n    'DATABASE_ERROR': ['Check database connectivity', 'Monitor storage capacity'],\n    'EMBEDDING_ERROR': ['Validate text content encoding', 'Check chunk size limits']\n  };\n  return tips[category] || ['Contact support for guidance'];\n}\n\nfunction generateDocumentationLinks(category) {\n  return [\n    '/docs/transcript-indexing',\n    '/docs/error-handling',\n    '/docs/api-reference'\n  ];\n}\n\nfunction getCommonSolutions(category) {\n  const solutions = {\n    'VALIDATION_ERROR': ['Check required fields', 'Validate data format'],\n    'API_ERROR': ['Verify credentials', 'Check rate limits'],\n    'DATABASE_ERROR': ['Check connectivity', 'Verify permissions'],\n    'EMBEDDING_ERROR': ['Reduce chunk size', 'Check content encoding']\n  };\n  return solutions[category] || ['Retry with corrected data'];\n}\n\nfunction generateTroubleshootingSteps(category) {\n  return [\n    'Review error message and category',\n    'Check all required fields are present',\n    'Verify data format and encoding',\n    'Test with smaller dataset if applicable',\n    'Contact support if issue persists'\n  ];\n}\n\nfunction getEscalationPath(severity) {\n  if (severity === 'high') return 'immediate_escalation';\n  if (severity === 'medium') return 'standard_support';\n  return 'self_service';\n}\n\nreturn [errorResponse];"
      },
      "id": "f2a3b4c5-d6e7-8901-f234-567890123456",
      "name": "‚ùå Error Response Handler",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [720, 600],
      "onError": "continueRegularOutput",
      "notes": "‚ùå COMPREHENSIVE ERROR RESPONSE SYSTEM\n\nüéØ PURPOSE:\nGenerates intelligent, actionable error responses for transcript indexing failures:\n‚Ä¢ Categorizes errors by type and severity for appropriate handling\n‚Ä¢ Provides detailed failure analysis with processing context\n‚Ä¢ Offers specific recovery guidance and retry recommendations\n‚Ä¢ Includes debugging information for technical troubleshooting\n‚Ä¢ Delivers comprehensive support resources and escalation paths\n\nüîç ERROR CATEGORIZATION:\n\nüìã VALIDATION_ERROR (Medium Severity):\n‚Ä¢ Missing required fields (videoId, transcript, title)\n‚Ä¢ Invalid data formats or encoding issues\n‚Ä¢ Content length violations (too short/long)\n‚Ä¢ Metadata structure problems\n\nüåê API_ERROR (High Severity):\n‚Ä¢ OpenAI API authentication failures\n‚Ä¢ Rate limit exceeded errors\n‚Ä¢ API service unavailability\n‚Ä¢ Network timeout issues\n\nüíæ DATABASE_ERROR (High Severity):\n‚Ä¢ PostgreSQL connection failures\n‚Ä¢ PGVector extension issues\n‚Ä¢ Storage capacity exceeded\n‚Ä¢ Transaction rollback problems\n\nüß† EMBEDDING_ERROR (High Severity):\n‚Ä¢ Model processing failures\n‚Ä¢ Token limit exceeded\n‚Ä¢ Content encoding issues\n‚Ä¢ Batch processing failures\n\n‚öôÔ∏è PROCESSING_ERROR (Medium Severity):\n‚Ä¢ Text chunking failures\n‚Ä¢ Memory allocation issues\n‚Ä¢ Timeout during processing\n‚Ä¢ Unexpected workflow interruptions\n\nüìä ERROR RESPONSE STRUCTURE:\n\nüö® ERROR DETAILS:\n‚Ä¢ Category and severity classification\n‚Ä¢ Specific error code and message\n‚Ä¢ Detailed technical information\n‚Ä¢ Stack trace for debugging\n\nüîÑ PROCESSING CONTEXT:\n‚Ä¢ Processing duration before failure\n‚Ä¢ Failure stage identification\n‚Ä¢ Partial results extraction\n‚Ä¢ Resource consumption metrics\n\n‚úÖ VALIDATION ANALYSIS:\n‚Ä¢ Field presence verification\n‚Ä¢ Data quality assessment\n‚Ä¢ Content length validation\n‚Ä¢ Format compliance checking\n\nüîß RECOVERY GUIDANCE:\n‚Ä¢ Retry recommendation logic\n‚Ä¢ Calculated retry delays\n‚Ä¢ Alternative approach suggestions\n‚Ä¢ Required corrective actions\n‚Ä¢ Prevention tips and best practices\n\nüêõ DEBUGGING SUPPORT:\n‚Ä¢ Unique request identification\n‚Ä¢ Workflow and node tracking\n‚Ä¢ API call counting\n‚Ä¢ Resource utilization metrics\n‚Ä¢ System load indicators\n\nüÜò SUPPORT RESOURCES:\n‚Ä¢ Relevant documentation links\n‚Ä¢ Common solution database\n‚Ä¢ Step-by-step troubleshooting\n‚Ä¢ Escalation path determination\n‚Ä¢ Contact information provision\n\nüéØ INTELLIGENT FEATURES:\n‚Ä¢ Severity-based retry logic\n‚Ä¢ Context-aware alternative suggestions\n‚Ä¢ Processing stage failure detection\n‚Ä¢ Resource usage estimation\n‚Ä¢ Escalation path automation\n\n‚û°Ô∏è VALUE DELIVERED:\nEmpowers users and support teams with comprehensive error analysis, clear recovery paths, and proactive problem-solving guidance"
    },
    {
      "parameters": {
        "jsCode": "// üìä SKIP INDEXING RESPONSE GENERATOR\n// Handles cases where indexing is skipped due to existing content\n\nconst originalRequest = items[0].json;\nconst existingRecord = $('Check Existing Index').first().json || {};\nconst timestamp = new Date().toISOString();\n\n// Generate skip response with detailed reasoning\nconst skipResponse = {\n  success: true,\n  operation: 'indexing_skipped',\n  timestamp: timestamp,\n  videoId: originalRequest.videoId,\n  title: originalRequest.title,\n  \n  // Skip Reasoning\n  skipReason: {\n    primary: 'existing_index_found',\n    details: 'Video transcript already indexed and up-to-date',\n    forceReindex: originalRequest.forceReindex || false,\n    lastIndexed: existingRecord.created_at,\n    daysSinceIndexing: calculateDaysSince(existingRecord.created_at),\n    indexFreshness: assessIndexFreshness(existingRecord.created_at)\n  },\n  \n  // Existing Index Information\n  existingIndex: {\n    id: existingRecord.id,\n    status: existingRecord.status,\n    chunkCount: existingRecord.chunk_count,\n    embeddingCount: existingRecord.embedding_count,\n    embeddingModel: existingRecord.embedding_model,\n    version: existingRecord.version,\n    createdAt: existingRecord.created_at,\n    updatedAt: existingRecord.updated_at\n  },\n  \n  // Search Capabilities\n  searchCapabilities: {\n    semanticSearch: true,\n    timestampSearch: true, // Assume available if previously indexed\n    metadataFiltering: !!existingRecord.metadata,\n    hybridSearch: true,\n    exactMatching: true,\n    searchReady: existingRecord.status === 'indexed'\n  },\n  \n  // Performance Savings\n  resourcesSaved: {\n    processingTimeSkipped: estimateProcessingTime(existingRecord.chunk_count),\n    apiCallsSkipped: Math.ceil(existingRecord.embedding_count / 100),\n    costSavings: estimateCostSavings(existingRecord.embedding_count),\n    co2Savings: estimateCO2Savings(existingRecord.embedding_count)\n  },\n  \n  // Content Analysis\n  contentAnalysis: {\n    alreadyOptimized: true,\n    searchOptimized: existingRecord.status === 'indexed',\n    qualityScore: calculateExistingQualityScore(existingRecord),\n    contentFreshness: assessContentFreshness(existingRecord.created_at)\n  },\n  \n  // Recommendations\n  recommendations: {\n    useExistingIndex: true,\n    forceReindexIfNeeded: originalRequest.forceReindex === false,\n    optimizationSuggestions: generateOptimizationSuggestions(existingRecord),\n    nextReindexingSuggested: suggestNextReindexing(existingRecord.created_at),\n    qualityImprovements: suggestQualityImprovements(existingRecord)\n  },\n  \n  // Alternative Actions\n  alternativeActions: {\n    forceReindex: {\n      available: true,\n      description: 'Set forceReindex=true to override existing index',\n      useCase: 'When transcript has been updated or improved'\n    },\n    updateMetadata: {\n      available: true,\n      description: 'Update metadata without reprocessing embeddings',\n      useCase: 'When only video metadata needs updating'\n    },\n    searchTest: {\n      available: true,\n      description: 'Test search functionality with existing index',\n      endpoint: '/api/search/semantic'\n    }\n  },\n  \n  // System Information\n  systemInfo: {\n    cacheHit: true,\n    processingSkipped: true,\n    resourcesConserved: true,\n    environmentalImpact: 'positive',\n    efficiency: 'optimized'\n  }\n};\n\n// Helper functions\nfunction calculateDaysSince(dateString) {\n  if (!dateString) return null;\n  const then = new Date(dateString);\n  const now = new Date();\n  const diffTime = Math.abs(now - then);\n  return Math.ceil(diffTime / (1000 * 60 * 60 * 24));\n}\n\nfunction assessIndexFreshness(dateString) {\n  const days = calculateDaysSince(dateString);\n  if (days === null) return 'unknown';\n  if (days < 1) return 'very_fresh';\n  if (days < 7) return 'fresh';\n  if (days < 30) return 'acceptable';\n  if (days < 90) return 'aging';\n  return 'stale';\n}\n\nfunction estimateProcessingTime(chunkCount) {\n  // Rough estimate: 100ms per chunk for full pipeline\n  return (chunkCount || 0) * 100;\n}\n\nfunction estimateCostSavings(embeddingCount) {\n  // text-embedding-3-small pricing estimation\n  const estimatedTokens = (embeddingCount || 0) * 250;\n  return Math.round((estimatedTokens / 1000) * 0.00002 * 100) / 100;\n}\n\nfunction estimateCO2Savings(embeddingCount) {\n  // Very rough estimate of CO2 savings from not processing\n  const apiCalls = Math.ceil((embeddingCount || 0) / 100);\n  return Math.round(apiCalls * 0.001 * 100) / 100; // kg CO2 estimate\n}\n\nfunction calculateExistingQualityScore(record) {\n  let score = 70; // Base score for existing index\n  if (record.status === 'indexed') score += 20;\n  if (record.chunk_count > 5) score += 10;\n  if (record.embedding_model === 'text-embedding-3-small') score += 5;\n  return Math.min(100, score);\n}\n\nfunction assessContentFreshness(dateString) {\n  const days = calculateDaysSince(dateString);\n  if (days === null) return 'unknown';\n  if (days < 30) return 'current';\n  if (days < 90) return 'recent';\n  return 'older';\n}\n\nfunction generateOptimizationSuggestions(record) {\n  const suggestions = [];\n  if (record.chunk_count < 5) {\n    suggestions.push('Consider reindexing with larger content for better search results');\n  }\n  if (!record.metadata || Object.keys(record.metadata).length === 0) {\n    suggestions.push('Add metadata for enhanced search filtering capabilities');\n  }\n  if (calculateDaysSince(record.created_at) > 90) {\n    suggestions.push('Consider reindexing with latest embedding models for improved quality');\n  }\n  return suggestions;\n}\n\nfunction suggestNextReindexing(dateString) {\n  const days = calculateDaysSince(dateString);\n  if (days === null) return 'as_needed';\n  if (days < 30) return 'not_needed_soon';\n  if (days < 90) return 'consider_in_30_days';\n  return 'recommended_soon';\n}\n\nfunction suggestQualityImprovements(record) {\n  const improvements = [];\n  improvements.push('Content is already optimized for current search capabilities');\n  if (record.embedding_model !== 'text-embedding-3-small') {\n    improvements.push('Reindex with latest embedding model for improved search quality');\n  }\n  return improvements;\n}\n\nreturn [skipResponse];"
      },
      "id": "a3b4c5d6-e7f8-9012-a345-678901234567",
      "name": "‚è≠Ô∏è Skip Indexing Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1160, 600],
      "onError": "continueRegularOutput",
      "notes": "‚è≠Ô∏è INTELLIGENT SKIP RESPONSE GENERATOR\n\nüéØ PURPOSE:\nHandles scenarios where transcript indexing is intelligently skipped:\n‚Ä¢ Provides detailed reasoning for skip decisions\n‚Ä¢ Analyzes existing index quality and freshness\n‚Ä¢ Calculates resource savings and environmental benefits\n‚Ä¢ Offers alternative actions and optimization suggestions\n‚Ä¢ Maintains transparency in automated decision-making\n\nüìä SKIP ANALYSIS:\n\nüîç SKIP REASONING:\n‚Ä¢ Primary reason identification (existing_index_found)\n‚Ä¢ Detailed explanation of decision logic\n‚Ä¢ forceReindex flag consideration\n‚Ä¢ Index freshness assessment (very_fresh to stale)\n‚Ä¢ Days since last indexing calculation\n\nüìã EXISTING INDEX EVALUATION:\n‚Ä¢ Index ID and status verification\n‚Ä¢ Chunk and embedding count analysis\n‚Ä¢ Embedding model version checking\n‚Ä¢ Creation and update timestamp tracking\n‚Ä¢ Version control information\n\nüîß SEARCH CAPABILITY ASSESSMENT:\n‚Ä¢ Semantic search availability confirmation\n‚Ä¢ Timestamp navigation capability\n‚Ä¢ Metadata filtering options assessment\n‚Ä¢ Hybrid search functionality verification\n‚Ä¢ Search readiness status validation\n\nüí∞ RESOURCE SAVINGS CALCULATION:\n‚Ä¢ Processing time savings estimation\n‚Ä¢ API call reduction quantification\n‚Ä¢ Cost savings computation (embedding API)\n‚Ä¢ CO2 footprint reduction estimation\n‚Ä¢ Environmental impact positive assessment\n\nüìà CONTENT ANALYSIS:\n‚Ä¢ Optimization status verification\n‚Ä¢ Search readiness confirmation\n‚Ä¢ Quality score calculation for existing content\n‚Ä¢ Content freshness assessment (current/recent/older)\n‚Ä¢ Performance optimization status\n\nüí° INTELLIGENT RECOMMENDATIONS:\n‚Ä¢ Use existing index confirmation\n‚Ä¢ Force reindexing guidance when needed\n‚Ä¢ Optimization suggestions based on analysis\n‚Ä¢ Next reindexing timeline recommendations\n‚Ä¢ Quality improvement opportunities\n\nüéØ ALTERNATIVE ACTIONS:\n‚Ä¢ Force reindex option explanation\n‚Ä¢ Metadata-only update possibilities\n‚Ä¢ Search functionality testing suggestions\n‚Ä¢ Use case scenarios for each alternative\n‚Ä¢ Endpoint information for testing\n\nüå± ENVIRONMENTAL BENEFITS:\n‚Ä¢ Resource conservation highlights\n‚Ä¢ Processing efficiency optimization\n‚Ä¢ Positive environmental impact notation\n‚Ä¢ Carbon footprint reduction quantification\n‚Ä¢ Sustainable AI practices demonstration\n\nüîÑ DECISION TRANSPARENCY:\n‚Ä¢ Clear skip reasoning explanation\n‚Ä¢ Objective quality metrics presentation\n‚Ä¢ Performance savings quantification\n‚Ä¢ Alternative path availability\n‚Ä¢ User control maintenance (force override)\n\nüìä BUSINESS VALUE:\n‚Ä¢ Cost optimization demonstration\n‚Ä¢ Resource efficiency improvement\n‚Ä¢ Environmental responsibility showcase\n‚Ä¢ System performance optimization\n‚Ä¢ User experience enhancement through speed\n\n‚û°Ô∏è OUTCOME:\nTransparent, intelligent skip decision with comprehensive analysis, resource savings, and clear alternative actions for users who need reindexing"
    }
  ],
  "connections": {
    "üì• Transcript Indexer Webhook": {
      "main": [
        [
          {
            "node": "‚úÖ Input Validator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "‚úÖ Input Validator": {
      "main": [
        [
          {
            "node": "üîç Check Existing Index",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "‚ùå Error Response Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "üîç Check Existing Index": {
      "main": [
        [
          {
            "node": "üîÄ Index Decision Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "üîÄ Index Decision Router": {
      "main": [
        [
          {
            "node": "üìù Process Transcript",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "‚è≠Ô∏è Skip Indexing Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "üìù Process Transcript": {
      "main": [
        [
          {
            "node": "üìö Load Document Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "üìö Load Document Chunks": {
      "main": [
        [
          {
            "node": "üß† Generate Embeddings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "üß† Generate Embeddings": {
      "main": [
        [
          {
            "node": "üíæ Store in PGVector",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "üíæ Store in PGVector": {
      "main": [
        [
          {
            "node": "üìù Update Transcript Record",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "üìù Update Transcript Record": {
      "main": [
        [
          {
            "node": "üì° Publish Index Event",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "üì° Publish Index Event": {
      "main": [
        [
          {
            "node": "üì§ Format Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [
    {
      "createdAt": "2025-01-30T12:00:00.000Z",
      "updatedAt": "2025-01-30T12:00:00.000Z",
      "id": "transcript-indexer",
      "name": "transcript-indexer"
    }
  ],
  "triggerCount": 1,
  "updatedAt": "2025-01-30T12:00:00.000Z",
  "versionId": "transcript-indexer-v1"
}